%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[11pt]{article}
\usepackage{hyperref} 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{color}

\newenvironment{EX}[2][Exercise]{\begin{trivlist}
\item[{\color{red} \hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}}]}{\end{trivlist}}

\newenvironment{SL}[1][Solution]{\begin{trivlist}
\item[{\color{blue} \hskip \labelsep {\bfseries #1:}}]}{\end{trivlist}}

% Define palette:
\definecolor{FC_Yellow}{cmyk}{0,0.06,1,0}
\definecolor{FC_Red}{rgb}{0.9294,0.1608,0.2235}
\definecolor{FC_Blue}{rgb}{0,0.3961,0.7412}
\definecolor{FC_Lime}{cmyk}{0.5,0,0.8,0}
\definecolor{FC_Green}{cmyk}{0.82,0,0.92,0}
\definecolor{FC_Cyan}{cmyk}{0.95,0,0.25,0}
\definecolor{FC_PurpleBlue}{cmyk}{0.53,0.65,0,0}
\definecolor{FC_PurpleRed}{cmyk}{0.22,0.72,0,0}
\definecolor{FC_Orange}{cmyk}{0,0.54,0.82,0}
\definecolor{FC_Grey}{cmyk}{0.1,0.11,0.13,0.36}


\begin{document}

% --------------------------------------------------------------
% Start here
% --------------------------------------------------------------

\noindent {\Large \bfseries CK0031: Homework 01} \hfill Matr\'icula (First-name Last-name) \\

\begin{EX}{01.01 (part of 02.03 AIMA3)}
For each of the following assertions, say whether it is \textit{true} or \textit{false} and support your answer with examples or counterexamples where appropriate.
\begin{itemize}
\item[a)] An agent that senses only partial information about the state cannot be perfectly rational [\textit{Hint}: Use the working definition of rationality.];
\item[b)] There exist task environments in which no pure reflex agent can behave rationally [\textit{Hint}: Think about the limitations of reflex agents.];
\item[c)] There exists a task environment in which every agent is rational [\textit{Hint}: Think about the usual properties of the task environment.];
\item[d)] The input to an agent program is the same as the input to the agent function;
\item[e)] Every agent function is implementable by some program/machine combination;
\item[f)] Suppose an agent selects its action uniformly at random from the set of possible actions. There exists a deterministic task environment in which this agent is rational [\textit{Hint}: Check question c).];
\item[g)] It is possible for a given agent to be perfectly rational in two distinct task environments;
\item[h)] Every agent is rational in an unobservable environment [\textit{Hint}: Think about the function of the model.];
\item[i)] A perfectly rational poker-playing agent never loses.
\end{itemize}
\end{EX}

%% \begin{SL}\
%% \end{SL}

% --------------------------------------------------------------
% Next exercise
% --------------------------------------------------------------

\begin{EX}{01.02 (part of 02.04 AIMA3)}
For each of the following activities, give a PEAS description of the task environment and characterise it in terms of the usual properties [i.e., i) Fully observable v partially observable; ii) Single agent v multi-agent; iii) deterministic v stochastic; iv) Episodic v sequential; v) Static v dynamic; vi) Discrete v continuous; and, vii) Known v unknown.]
\begin{itemize}
\item[a)] Playing soccer;
\item[b)] Shopping for used AI books on the Internet;
\item[c)] Playing a tennis match;
\item[d)] Practicing tennis against a wall;
\item[e)] Performing a high jump;
\item[f)] Bidding on an item at an auction.
\end{itemize}
\end{EX}

%% \begin{SL}\
%% \end{SL}

% --------------------------------------------------------------
% Next exercise
% --------------------------------------------------------------

\begin{EX}{01.03 (02.05 AIMA3)}
Define in your own words the following terms: 
\begin{itemize}
\item[a)] agent;
\item[b)] agent function;
\item[c)] agent program;
\item[d)] rationality; 
\item[e)] autonomy;
\item[f)] reflex agent
\item[g)] model-based agent;
\item[h)] goal-based agent;
\item[i)] utility-based agent;
\item[j)] learning agent.
\end{itemize}
\end{EX}

%%b\begin{SL}\
%%b\end{SL}

% --------------------------------------------------------------
% Next exercise
% --------------------------------------------------------------

\begin{EX}{01.04 (part of 02.06 AIMA3)}
This exercise explores the differences between agent functions and agent programs.
\begin{enumerate}
\item[a)] Can there be more than one agent program that implements a given agent function? Give an example, or show why one is not possible.
\item[b)] Given a fixed machine architecture, does each agent program implement exactly one agent function?
\item[c)] Suppose we keep the agent program fixed but speed up the machine by a factor of two. Does that change the agent function? [\textit{Hint}: Consider whether the environment is static or dynamic.]
\end{enumerate}
\end{EX}

%% \begin{SL}\
%% \end{SL}

% --------------------------------------------------------------
% Next exercise
% --------------------------------------------------------------


\begin{EX}{01.05}
Recently, an earthquake, measuring 6.2 $\pm$ 0.016 hit Central Italy on 24 August 2016. at 03:36:32 CEST (01:36 UTC). Early reports indicated severe damage in the town of Amatrice. You, as a trainee, was called up to develop an intelligent agent able to remove people from a region inaccessible to humans in Amatrice. This rescuer agent runs on a drone and is described as follows:

\begin{itemize}
\item {\bf  Percepts}: Each rescue agent gets a three-element percept vector on each turn. The first element, the proximity sensor, should be 1 if the droid is in front of a wall or a rock (in the direction that the droid has). The second comes from the presence sensor under the machine, which emits 1 if there is human there and 0 otherwise. The third comes from an infrared sensor, which emits 1 when the agent have to take off (and go back to the paramedics), and 0 otherwise.

\item {\bf Actions}: There are five actions available: Go forward, turn right by 90$^{\circ}$, turn left by 90$^{\circ}$, grab a human and take off.

\item {\bf Goals}: The goal for each agent is to rescue people  and go home. To be precise, the performance measure will be 100 points for each person rescued, minus 1 point for each action taken.

\item {\bf Environment}: The environment consists of a grid of squares. Some squares contain obstacles (walls around and some rock structures) and other squares are open space. Some of the open squares contain humans. Make sure that each square only contains or a human or a rock or is empty. Each ``go forward" action moves one square unless there is an obstacle (wall or rock) in that square, in which case the agent, have to turn. A``grab human" action always rescue a human. A ``take off" command ends the simulation.

\end{itemize}


Design and implement of a Model Based Agent for the aforementioned environment and measure its performance. Remember that the Model Based Agent also can 'remember' things that made in the past and note that there'll many Models that can achieve the problem. The environment is a  $15 \times 20$ rectangular room, where each square has a 10\% chance of containing human (30 humans), 33\% chance of containing a rock (100 rocks). Also remember to represent the walls around the rectangular room.
Explain why it is impossible to have a Reflex Agent that when receives the take off signal returns to the entrance and just takes off. Speculate on what the best possible reflex agent could do. What prevents a Reflex agent from doing very well?
\end{EX}

\begin{EX}{01.06}

Made several Agents and Environments defined int the Exercise 01.05 and Measure their performance. How close do they come to the ideal agent for this earthquake environment?
\end{EX}

You can implement the code in Python or Java, using the code that is provided in the site

\href{https://github.com/juliosibaja/IA2016.2/tree/master/lista1/}{GitHub Lista 1}
%% \begin{SL}\
%% \end{SL}

% --------------------------------------------------------------
% Stop here
% --------------------------------------------------------------

\end{document}